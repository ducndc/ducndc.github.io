---
layout: post
title: "Logging and Log Management"
date: 2025-07-24 10:00:00 +0700
categories: [Programming]
---

Good logging is the difference between diagnosing a production issue in minutes and spending hours in the dark. Yet logging is one of those things that's easy to do badly — either too much, too little, or at the wrong level. This post covers the foundations: what log data is, how log messages are structured, how to manage retention, and the principles that make a logging system genuinely useful.

---

## Log Levels

Log data carries intrinsic meaning — it tells you *why* a message was generated, not just that something happened. The level attached to a message is a statement about severity and urgency. Using levels consistently is what allows you to filter signal from noise.

### Debug

Debug messages help developers trace execution during development and troubleshooting. They are the most verbose level and typically include variable values, pointer addresses, and internal processing flow details. Debug logging is almost always disabled in production — the volume would be overwhelming, and the output can expose internal implementation details.

### Information

Info-level messages confirm that the system is working as expected. They record significant but routine events: a service starting up, a user authenticating, a device connecting to the network. For example, when a station associates with a Wi-Fi access point, an info log might record the MAC address, connection type, and supported standards. These messages are useful for auditing and operational visibility without signaling that anything is wrong.

### Warning

Warnings indicate that something unexpected happened, but the system recovered and continues to operate. Common examples include a physical port disconnecting and reconnecting, packet retransmissions, an optional configuration parameter being absent, or a mesh network device temporarily leaving the network.

Warnings are early indicators. They rarely require immediate action, but a pattern of warnings often precedes a more serious failure. Knowing when to use this level requires understanding the full operational flow of your system — a good warning tells an operator "you should be aware of this" without demanding they act right now.

### Error

Error logs report failures that require attention. The system was unable to do something it was supposed to do: a buffer flush to disk failed, a null pointer was dereferenced, data arrived in a corrupted state, or a subsystem behaved outside its designed parameters. Errors don't necessarily bring the system down, but they indicate something has gone wrong and should be investigated.

A common mistake is logging too many things at the error level. If every minor issue is an error, genuine errors become hard to find. Reserve this level for actual failures.

### Alert

Alerts are for critical failures that threaten the continued operation of the system. If essential configuration data for a core daemon cannot be retrieved at startup, the system cannot function correctly — that warrants an alert. Alert-level messages should be rare by design. If your system is generating many alerts during normal operation, the level is being misused.

---

## Structure of a Log Message

A log message has three components:

### Timestamp

The timestamp records *when* the event occurred — typically year, month, day, and time down to the millisecond. Accurate timestamps are essential for correlating events across systems. A common pitfall: if the system clock is unsynchronized at boot (for instance, the device starts without internet access), timestamps may be wrong or epoch-relative until NTP synchronizes. Incorrect timestamps make root cause analysis much harder.

### Source

The source identifies *what generated the message* — usually the process name and log level, and optionally the function name and source file line number. Function and line information is valuable during development but is typically stripped from production logs to reduce volume and avoid leaking internal source code structure.

### Data

The message body is where most of the quality problems live. Log data must be meaningful without being excessive. A message that says `"error occurred"` is useless. A message that dumps an entire data structure on every function call is noise. The right amount of data depends on the log level: debug logs can be verbose; error logs should give enough context to start an investigation without requiring another reproduction.

---

## Log Transmission and Collection

Every device or application implements a logging subsystem that generates messages when relevant events occur. Those messages need to go somewhere useful.

A **loghost** — a centralized Unix or Windows system — collects log messages from multiple sources. Centralizing logs provides three practical benefits: a single place to search across systems, a reliable location for backups, and a platform for analysis tools to operate on consistent data.

---

## Log Retention Policy

Retention decisions determine how long logs are kept and where they're stored. Getting this wrong is expensive in both directions: keeping everything forever is costly and legally risky; deleting too soon leaves you unable to investigate incidents after the fact.

Four factors drive retention policy:

**Compliance requirements** are the floor. Many industries have mandatory minimums — PCI DSS requires one year of log retention (section 10.7); NERC specifies different durations for different log types. These define the minimum you must keep, not the maximum.

**Organizational risk** determines where you need more. Insider threat investigations can span years — logs that look unremarkable today may be critical evidence in an investigation that begins three years from now. High-risk environments need longer retention windows.

**Log source and volume** affect what's practical. A high-traffic core firewall may generate enormous log volumes; keeping them for a year may be cost-prohibitive without compliance requiring it. Custom applications or legacy systems may produce logs in formats that your analysis tools can't parse, making retention less useful regardless of duration.

**Storage options** constrain cost and accessibility. Common options include local disk, WORM media, tape, relational databases, dedicated log archives, and cloud storage. Tape is inexpensive but slow and manually intensive to retrieve. Cheap optical media degrades over time and may be unreadable in seven years. Cloud storage is increasingly practical for long-term archiving. Whatever you choose, logs must remain retrievable within a reasonable timeframe — a backup that takes weeks to restore provides little operational value.

---

## Principles of Log Management

### Collect with purpose

Don't collect log data you don't intend to use. Every log source adds storage cost, processing overhead, and noise. Collect logs for clearly defined purposes — troubleshooting, security analysis, compliance — and resist the urge to log "just in case." The same discipline applies to generating logs: don't instrument code paths that will never be reviewed.

### Retain only what's necessary

Keep logs as long as they remain useful, or longer if required by law. Don't default to storing everything indefinitely. Define retention windows per log type based on the factors above, and enforce deletion when those windows expire.

### Log broadly, alert selectively

Log volumes can reach petabytes. Human attention is finite — a reasonable operations team might respond to a dozen alerts per day before alert fatigue sets in. Don't conflate logging with alerting. The operating principle:

> **Log everything worth recording. Store important error logs. Alert only on conditions that require human action.**

Alerts that don't require action train people to ignore alerts.

### Protect logs proportionally

Log data is valuable — it may contain sensitive user information, security events, or evidence of breaches. But don't protect logs more heavily than you protect the business data they describe. Reasonable measures include hashing logs to detect tampering, applying access controls appropriate to the data's sensitivity, and avoiding encryption unless the log content itself warrants it (encryption adds cost and complicates troubleshooting).

### Treat logging as a living system

Log sources, log formats, and operational needs change continuously as software evolves and deployments shift. A logging setup that was appropriate a year ago may be collecting the wrong things today. Periodically review your log policies and collection configuration, update parsers and analysis tools when log formats change, and document how logs are generated so that knowledge doesn't live only in the heads of the original developers.